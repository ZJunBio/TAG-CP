{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbf87e-bc17-4a9f-9998-c19b0eaad93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD(learning_rate = 0.01), 1000epochs, batch_size = 128, mom = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac2080a-d3c4-45c6-969e-3abf885e78aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:08:37.313356: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-11 22:08:37.313385: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV, KFold\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3948f03-ee62-4edb-b2bf-fe7f88b7450c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85c16fc-0153-4bc8-88f5-9feb0593c0c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ = preprocessing.normalize(np.load(\"../data/datasets/train_tensor_csigma005.npy\", allow_pickle=True))\n",
    "valid_ = preprocessing.normalize(np.load(\"../data/datasets/val_tensor_csigma005.npy\", allow_pickle=True))\n",
    "test = preprocessing.normalize(np.load(\"../data/datasets/test_tensor_csigma005.npy\", allow_pickle=True))\n",
    "train_lab_ = np.load(\"../data/datasets/train_label_csima005.npy\", allow_pickle=True)\n",
    "valid_lab_ = np.load(\"../data/datasets/val_label_csima005.npy\", allow_pickle=True)\n",
    "test_lab = np.load(\"../data/datasets/test_label_csima005.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7085d2-1762-4fec-af92-40185047c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0065816-20fe-4741-9ddc-cd4cec11d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((train_, valid_))\n",
    "train_lab = np.concatenate((train_lab_, valid_lab_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacbe1c9-25ec-4a44-84ec-fd0571b86168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33467, 841) (3720, 841)\n",
      "(33467,) (3720,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test.shape)\n",
    "print(train_lab.shape, test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c7f63a-622c-4415-a0cf-515fcf7c1c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.L1 = 1024\n",
    "        self.L2 = 512\n",
    "        self.L3 = 256\n",
    "        self.L4 = 128\n",
    "        self.L5 = 64\n",
    "        self.L6 = 10\n",
    "        self.outl = 1\n",
    "        self.act = \"relu\"\n",
    "        self.outact = \"sigmoid\"\n",
    "        self.batch_size = 256 # can not used in model.fit() when input is a tenforflow dataset\n",
    "        self.validation_batch_size  = 256 #Only used in dataset.batch()\n",
    "        self.epochs = 500\n",
    "        self.validation_split = 0.2 # this parameter not surported for tf.data.Dataset\n",
    "        self.steps_per = 100\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b3bcb9-c1e8-466c-9288-de24b7b29c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode = 'min', patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a047cfa-ca8a-488f-aebb-d7b6169fd6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:09:38.920691: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-11 22:09:38.920728: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-11 22:09:38.920748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (618849): /proc/driver/nvidia/version does not exist\n",
      "2023-08-11 22:09:38.921103: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               431104    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 10)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 582,909\n",
      "Trainable params: 581,225\n",
      "Non-trainable params: 1,684\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 4s 27ms/step - loss: 1.2529 - auc: 0.5824 - val_loss: 0.6870 - val_auc: 0.5000\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.1494 - auc: 0.7035 - val_loss: 0.6876 - val_auc: 0.5094\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.1093 - auc: 0.7323 - val_loss: 0.6903 - val_auc: 0.5556\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0770 - auc: 0.7612 - val_loss: 0.7113 - val_auc: 0.5866\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0639 - auc: 0.7626 - val_loss: 0.7343 - val_auc: 0.5824\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0356 - auc: 0.7723 - val_loss: 0.7125 - val_auc: 0.6308\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0248 - auc: 0.7831 - val_loss: 0.6655 - val_auc: 0.7302\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0022 - auc: 0.7957 - val_loss: 0.6400 - val_auc: 0.7741\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9962 - auc: 0.7963 - val_loss: 0.6378 - val_auc: 0.7847\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9722 - auc: 0.8131 - val_loss: 0.6046 - val_auc: 0.7840\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9626 - auc: 0.8140 - val_loss: 0.5936 - val_auc: 0.7871\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9514 - auc: 0.8153 - val_loss: 0.6142 - val_auc: 0.7927\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9472 - auc: 0.8229 - val_loss: 0.5968 - val_auc: 0.7952\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9362 - auc: 0.8260 - val_loss: 0.5863 - val_auc: 0.8015\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.9208 - auc: 0.8350 - val_loss: 0.5752 - val_auc: 0.8079\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9167 - auc: 0.8358 - val_loss: 0.5624 - val_auc: 0.8063\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9031 - auc: 0.8371 - val_loss: 0.5532 - val_auc: 0.8129\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8923 - auc: 0.8498 - val_loss: 0.5658 - val_auc: 0.8103\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8738 - auc: 0.8517 - val_loss: 0.5327 - val_auc: 0.8129\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.8823 - auc: 0.8493 - val_loss: 0.5582 - val_auc: 0.8127\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8695 - auc: 0.8551 - val_loss: 0.5360 - val_auc: 0.8224\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8622 - auc: 0.8591 - val_loss: 0.5131 - val_auc: 0.8244\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8446 - auc: 0.8656 - val_loss: 0.5188 - val_auc: 0.8191\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8489 - auc: 0.8621 - val_loss: 0.4843 - val_auc: 0.8173\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8285 - auc: 0.8730 - val_loss: 0.5126 - val_auc: 0.8214\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8209 - auc: 0.8746 - val_loss: 0.5278 - val_auc: 0.8217\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8240 - auc: 0.8721 - val_loss: 0.4968 - val_auc: 0.8174\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8088 - auc: 0.8796 - val_loss: 0.4816 - val_auc: 0.8256\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8070 - auc: 0.8809 - val_loss: 0.5314 - val_auc: 0.8271\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7821 - auc: 0.8894 - val_loss: 0.4860 - val_auc: 0.8250\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7838 - auc: 0.8876 - val_loss: 0.4766 - val_auc: 0.8237\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7774 - auc: 0.8894 - val_loss: 0.4800 - val_auc: 0.8252\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7813 - auc: 0.8918 - val_loss: 0.4960 - val_auc: 0.8314\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7605 - auc: 0.8941 - val_loss: 0.4916 - val_auc: 0.8295\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7633 - auc: 0.8924 - val_loss: 0.4871 - val_auc: 0.8290\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7490 - auc: 0.9003 - val_loss: 0.4982 - val_auc: 0.8312\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7520 - auc: 0.8997 - val_loss: 0.4334 - val_auc: 0.8302\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7317 - auc: 0.9020 - val_loss: 0.4464 - val_auc: 0.8205\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7248 - auc: 0.9076 - val_loss: 0.4840 - val_auc: 0.8313\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7260 - auc: 0.9053 - val_loss: 0.4718 - val_auc: 0.8332\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7238 - auc: 0.9077 - val_loss: 0.4253 - val_auc: 0.8294\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7095 - auc: 0.9091 - val_loss: 0.5080 - val_auc: 0.8324\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7091 - auc: 0.9109 - val_loss: 0.4384 - val_auc: 0.8298\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6893 - auc: 0.9187 - val_loss: 0.4627 - val_auc: 0.8340\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6891 - auc: 0.9206 - val_loss: 0.4521 - val_auc: 0.8305\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6692 - auc: 0.9204 - val_loss: 0.4106 - val_auc: 0.8405\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6784 - auc: 0.9218 - val_loss: 0.4385 - val_auc: 0.8216\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6658 - auc: 0.9228 - val_loss: 0.4293 - val_auc: 0.8321\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6707 - auc: 0.9208 - val_loss: 0.4268 - val_auc: 0.8339\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6489 - auc: 0.9275 - val_loss: 0.4689 - val_auc: 0.8261\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6574 - auc: 0.9251 - val_loss: 0.4113 - val_auc: 0.8282\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6389 - auc: 0.9311 - val_loss: 0.4391 - val_auc: 0.8344\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6338 - auc: 0.9313 - val_loss: 0.3793 - val_auc: 0.8319\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6470 - auc: 0.9271 - val_loss: 0.4104 - val_auc: 0.8335\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6345 - auc: 0.9296 - val_loss: 0.3884 - val_auc: 0.8234\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6196 - auc: 0.9343 - val_loss: 0.4173 - val_auc: 0.8264\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6281 - auc: 0.9309 - val_loss: 0.4178 - val_auc: 0.8205\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6110 - auc: 0.9375 - val_loss: 0.4658 - val_auc: 0.8374\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6011 - auc: 0.9379 - val_loss: 0.3745 - val_auc: 0.8281\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6023 - auc: 0.9379 - val_loss: 0.3459 - val_auc: 0.8338\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5979 - auc: 0.9384 - val_loss: 0.4045 - val_auc: 0.8251\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5888 - auc: 0.9411 - val_loss: 0.3759 - val_auc: 0.8319\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5849 - auc: 0.9420 - val_loss: 0.4139 - val_auc: 0.8272\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5860 - auc: 0.9419 - val_loss: 0.4075 - val_auc: 0.8342\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5663 - auc: 0.9446 - val_loss: 0.4130 - val_auc: 0.8313\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5695 - auc: 0.9451 - val_loss: 0.4568 - val_auc: 0.8403\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5752 - auc: 0.9432 - val_loss: 0.4663 - val_auc: 0.8380\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5607 - auc: 0.9450 - val_loss: 0.3908 - val_auc: 0.8281\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5643 - auc: 0.9454 - val_loss: 0.3732 - val_auc: 0.8351\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5498 - auc: 0.9485 - val_loss: 0.3464 - val_auc: 0.8309\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5632 - auc: 0.9433 - val_loss: 0.3489 - val_auc: 0.8288\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5278 - auc: 0.9531 - val_loss: 0.3685 - val_auc: 0.8288\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.5559 - auc: 0.9473 - val_loss: 0.3761 - val_auc: 0.8366\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5447 - auc: 0.9491 - val_loss: 0.4348 - val_auc: 0.8289\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5401 - auc: 0.9478 - val_loss: 0.3448 - val_auc: 0.8290\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5220 - auc: 0.9534 - val_loss: 0.3991 - val_auc: 0.8379\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5185 - auc: 0.9534 - val_loss: 0.4028 - val_auc: 0.8324\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5093 - auc: 0.9561 - val_loss: 0.3406 - val_auc: 0.8330\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5221 - auc: 0.9516 - val_loss: 0.4326 - val_auc: 0.8303\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5083 - auc: 0.9550 - val_loss: 0.3290 - val_auc: 0.8312\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5160 - auc: 0.9545 - val_loss: 0.4057 - val_auc: 0.8282\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5029 - auc: 0.9560 - val_loss: 0.3615 - val_auc: 0.8235\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5029 - auc: 0.9554 - val_loss: 0.3574 - val_auc: 0.8369\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4938 - auc: 0.9579 - val_loss: 0.3826 - val_auc: 0.8344\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4981 - auc: 0.9560 - val_loss: 0.4252 - val_auc: 0.8285\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4917 - auc: 0.9579 - val_loss: 0.3911 - val_auc: 0.8353\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4920 - auc: 0.9568 - val_loss: 0.3777 - val_auc: 0.8301\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4793 - auc: 0.9584 - val_loss: 0.4139 - val_auc: 0.8415\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4905 - auc: 0.9572 - val_loss: 0.3834 - val_auc: 0.8294\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4795 - auc: 0.9587 - val_loss: 0.3985 - val_auc: 0.8338\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4721 - auc: 0.9609 - val_loss: 0.3062 - val_auc: 0.8230\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4669 - auc: 0.9611 - val_loss: 0.3223 - val_auc: 0.8414\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4724 - auc: 0.9605 - val_loss: 0.3794 - val_auc: 0.8398\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4480 - auc: 0.9639 - val_loss: 0.3320 - val_auc: 0.8329\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4788 - auc: 0.9584 - val_loss: 0.4077 - val_auc: 0.8283\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4510 - auc: 0.9631 - val_loss: 0.3163 - val_auc: 0.8327\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4508 - auc: 0.9634 - val_loss: 0.3490 - val_auc: 0.8324\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4501 - auc: 0.9627 - val_loss: 0.2879 - val_auc: 0.8347\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4492 - auc: 0.9634 - val_loss: 0.4049 - val_auc: 0.8320\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4451 - auc: 0.9636 - val_loss: 0.3683 - val_auc: 0.8380\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4409 - auc: 0.9635 - val_loss: 0.3540 - val_auc: 0.8289\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4401 - auc: 0.9643 - val_loss: 0.3937 - val_auc: 0.8380\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4390 - auc: 0.9649 - val_loss: 0.3208 - val_auc: 0.8318\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4336 - auc: 0.9651 - val_loss: 0.3675 - val_auc: 0.8281\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4256 - auc: 0.9666 - val_loss: 0.3848 - val_auc: 0.8391\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4409 - auc: 0.9638 - val_loss: 0.4505 - val_auc: 0.8194\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4185 - auc: 0.9670 - val_loss: 0.3885 - val_auc: 0.8268\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4229 - auc: 0.9664 - val_loss: 0.4038 - val_auc: 0.8423\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4532 - auc: 0.9597 - val_loss: 0.3884 - val_auc: 0.8266\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4430 - auc: 0.9623 - val_loss: 0.4602 - val_auc: 0.8207\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4175 - auc: 0.9669 - val_loss: 0.3090 - val_auc: 0.8080\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4481 - auc: 0.9612 - val_loss: 0.4010 - val_auc: 0.8349\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4092 - auc: 0.9684 - val_loss: 0.3534 - val_auc: 0.8204\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3007 - auc: 0.9149\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 512)               431104    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 10)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 582,909\n",
      "Trainable params: 581,225\n",
      "Non-trainable params: 1,684\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 4s 29ms/step - loss: 1.2414 - auc_1: 0.6305 - val_loss: 0.8121 - val_auc_1: 0.5000\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.1430 - auc_1: 0.7235 - val_loss: 0.8813 - val_auc_1: 0.5024\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0856 - auc_1: 0.7622 - val_loss: 0.9180 - val_auc_1: 0.5669\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0612 - auc_1: 0.7719 - val_loss: 0.9142 - val_auc_1: 0.6044\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0343 - auc_1: 0.7839 - val_loss: 0.8370 - val_auc_1: 0.6512\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0071 - auc_1: 0.7920 - val_loss: 0.7377 - val_auc_1: 0.6932\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9932 - auc_1: 0.8017 - val_loss: 0.6618 - val_auc_1: 0.7486\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.9731 - auc_1: 0.8090 - val_loss: 0.6641 - val_auc_1: 0.7613\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9545 - auc_1: 0.8198 - val_loss: 0.6474 - val_auc_1: 0.7719\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9604 - auc_1: 0.8095 - val_loss: 0.6145 - val_auc_1: 0.7748\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9248 - auc_1: 0.8315 - val_loss: 0.6031 - val_auc_1: 0.7748\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9237 - auc_1: 0.8265 - val_loss: 0.5989 - val_auc_1: 0.7818\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.9168 - auc_1: 0.8337 - val_loss: 0.5666 - val_auc_1: 0.7862\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9021 - auc_1: 0.8399 - val_loss: 0.5801 - val_auc_1: 0.7894\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8918 - auc_1: 0.8452 - val_loss: 0.5853 - val_auc_1: 0.7912\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8833 - auc_1: 0.8476 - val_loss: 0.5658 - val_auc_1: 0.7952\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.8651 - auc_1: 0.8535 - val_loss: 0.5639 - val_auc_1: 0.7924\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8582 - auc_1: 0.8598 - val_loss: 0.5424 - val_auc_1: 0.7942\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.8500 - auc_1: 0.8574 - val_loss: 0.5524 - val_auc_1: 0.7938\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8418 - auc_1: 0.8657 - val_loss: 0.5489 - val_auc_1: 0.8000\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8385 - auc_1: 0.8645 - val_loss: 0.5298 - val_auc_1: 0.7983\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8252 - auc_1: 0.8725 - val_loss: 0.5251 - val_auc_1: 0.8020\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8150 - auc_1: 0.8744 - val_loss: 0.5353 - val_auc_1: 0.7990\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8162 - auc_1: 0.8723 - val_loss: 0.5233 - val_auc_1: 0.8172\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7972 - auc_1: 0.8811 - val_loss: 0.4861 - val_auc_1: 0.8102\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7849 - auc_1: 0.8854 - val_loss: 0.5075 - val_auc_1: 0.8130\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7902 - auc_1: 0.8823 - val_loss: 0.5318 - val_auc_1: 0.8056\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7751 - auc_1: 0.8894 - val_loss: 0.4982 - val_auc_1: 0.8144\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7682 - auc_1: 0.8922 - val_loss: 0.4761 - val_auc_1: 0.8112\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7626 - auc_1: 0.8921 - val_loss: 0.4929 - val_auc_1: 0.8159\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7554 - auc_1: 0.8930 - val_loss: 0.4952 - val_auc_1: 0.8163\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7489 - auc_1: 0.8979 - val_loss: 0.4575 - val_auc_1: 0.8178\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7504 - auc_1: 0.9007 - val_loss: 0.4665 - val_auc_1: 0.8191\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7359 - auc_1: 0.8986 - val_loss: 0.4819 - val_auc_1: 0.8217\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7236 - auc_1: 0.9060 - val_loss: 0.4644 - val_auc_1: 0.8224\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7181 - auc_1: 0.9082 - val_loss: 0.4438 - val_auc_1: 0.8198\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7193 - auc_1: 0.9087 - val_loss: 0.4814 - val_auc_1: 0.8216\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7082 - auc_1: 0.9067 - val_loss: 0.4473 - val_auc_1: 0.8253\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7082 - auc_1: 0.9089 - val_loss: 0.4634 - val_auc_1: 0.8173\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6924 - auc_1: 0.9157 - val_loss: 0.4580 - val_auc_1: 0.8252\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6963 - auc_1: 0.9149 - val_loss: 0.4414 - val_auc_1: 0.8201\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6795 - auc_1: 0.9168 - val_loss: 0.4323 - val_auc_1: 0.8210\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6785 - auc_1: 0.9189 - val_loss: 0.4621 - val_auc_1: 0.8211\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6711 - auc_1: 0.9209 - val_loss: 0.4452 - val_auc_1: 0.8171\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6751 - auc_1: 0.9211 - val_loss: 0.4738 - val_auc_1: 0.8282\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6506 - auc_1: 0.9237 - val_loss: 0.4171 - val_auc_1: 0.8266\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6683 - auc_1: 0.9214 - val_loss: 0.4383 - val_auc_1: 0.8258\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6485 - auc_1: 0.9253 - val_loss: 0.4425 - val_auc_1: 0.8229\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6463 - auc_1: 0.9263 - val_loss: 0.4148 - val_auc_1: 0.8336\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6309 - auc_1: 0.9307 - val_loss: 0.4706 - val_auc_1: 0.8294\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6374 - auc_1: 0.9288 - val_loss: 0.4473 - val_auc_1: 0.8334\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6229 - auc_1: 0.9335 - val_loss: 0.4883 - val_auc_1: 0.8247\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6112 - auc_1: 0.9362 - val_loss: 0.4111 - val_auc_1: 0.8300\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6287 - auc_1: 0.9308 - val_loss: 0.3756 - val_auc_1: 0.8293\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6160 - auc_1: 0.9332 - val_loss: 0.4601 - val_auc_1: 0.8263\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.6100 - auc_1: 0.9351 - val_loss: 0.4063 - val_auc_1: 0.8306\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6020 - auc_1: 0.9366 - val_loss: 0.4200 - val_auc_1: 0.8273\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5985 - auc_1: 0.9392 - val_loss: 0.4960 - val_auc_1: 0.8286\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5849 - auc_1: 0.9412 - val_loss: 0.3615 - val_auc_1: 0.8212\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5897 - auc_1: 0.9398 - val_loss: 0.3922 - val_auc_1: 0.8329\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5872 - auc_1: 0.9397 - val_loss: 0.4456 - val_auc_1: 0.8272\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5778 - auc_1: 0.9422 - val_loss: 0.4084 - val_auc_1: 0.8277\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5705 - auc_1: 0.9438 - val_loss: 0.4086 - val_auc_1: 0.8326\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5724 - auc_1: 0.9443 - val_loss: 0.4453 - val_auc_1: 0.8311\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5490 - auc_1: 0.9481 - val_loss: 0.4074 - val_auc_1: 0.8375\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5672 - auc_1: 0.9437 - val_loss: 0.3702 - val_auc_1: 0.8322\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5584 - auc_1: 0.9467 - val_loss: 0.3992 - val_auc_1: 0.8288\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5522 - auc_1: 0.9459 - val_loss: 0.3967 - val_auc_1: 0.8227\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5491 - auc_1: 0.9481 - val_loss: 0.4065 - val_auc_1: 0.8246\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5437 - auc_1: 0.9486 - val_loss: 0.3903 - val_auc_1: 0.8291\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5403 - auc_1: 0.9487 - val_loss: 0.3773 - val_auc_1: 0.8387\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5313 - auc_1: 0.9503 - val_loss: 0.3486 - val_auc_1: 0.8262\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5289 - auc_1: 0.9536 - val_loss: 0.3794 - val_auc_1: 0.8345\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5340 - auc_1: 0.9509 - val_loss: 0.4159 - val_auc_1: 0.8290\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5211 - auc_1: 0.9515 - val_loss: 0.3851 - val_auc_1: 0.8236\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5155 - auc_1: 0.9543 - val_loss: 0.4273 - val_auc_1: 0.8273\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5184 - auc_1: 0.9528 - val_loss: 0.4825 - val_auc_1: 0.8304\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5220 - auc_1: 0.9516 - val_loss: 0.3690 - val_auc_1: 0.8227\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5067 - auc_1: 0.9547 - val_loss: 0.4174 - val_auc_1: 0.8338\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5068 - auc_1: 0.9547 - val_loss: 0.3474 - val_auc_1: 0.8192\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5076 - auc_1: 0.9556 - val_loss: 0.4021 - val_auc_1: 0.8328\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5089 - auc_1: 0.9533 - val_loss: 0.3820 - val_auc_1: 0.8282\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5007 - auc_1: 0.9549 - val_loss: 0.4433 - val_auc_1: 0.8319\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4908 - auc_1: 0.9580 - val_loss: 0.3459 - val_auc_1: 0.8213\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4931 - auc_1: 0.9570 - val_loss: 0.4094 - val_auc_1: 0.8394\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4857 - auc_1: 0.9585 - val_loss: 0.3752 - val_auc_1: 0.8320\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4858 - auc_1: 0.9576 - val_loss: 0.3406 - val_auc_1: 0.8322\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4715 - auc_1: 0.9597 - val_loss: 0.3547 - val_auc_1: 0.8303\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4865 - auc_1: 0.9580 - val_loss: 0.3731 - val_auc_1: 0.8346\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4720 - auc_1: 0.9602 - val_loss: 0.4056 - val_auc_1: 0.8367\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4733 - auc_1: 0.9603 - val_loss: 0.3384 - val_auc_1: 0.8323\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4649 - auc_1: 0.9611 - val_loss: 0.4098 - val_auc_1: 0.8327\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4856 - auc_1: 0.9572 - val_loss: 0.3446 - val_auc_1: 0.8407\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4542 - auc_1: 0.9622 - val_loss: 0.3705 - val_auc_1: 0.8368\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4594 - auc_1: 0.9634 - val_loss: 0.3767 - val_auc_1: 0.8378\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4593 - auc_1: 0.9612 - val_loss: 0.3178 - val_auc_1: 0.8318\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4471 - auc_1: 0.9641 - val_loss: 0.3743 - val_auc_1: 0.8254\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4491 - auc_1: 0.9633 - val_loss: 0.3970 - val_auc_1: 0.8484\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4460 - auc_1: 0.9650 - val_loss: 0.3616 - val_auc_1: 0.8347\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4405 - auc_1: 0.9645 - val_loss: 0.3567 - val_auc_1: 0.8405\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4318 - auc_1: 0.9657 - val_loss: 0.3450 - val_auc_1: 0.8363\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4440 - auc_1: 0.9641 - val_loss: 0.3008 - val_auc_1: 0.8306\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4445 - auc_1: 0.9637 - val_loss: 0.5560 - val_auc_1: 0.8240\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4454 - auc_1: 0.9629 - val_loss: 0.3410 - val_auc_1: 0.8341\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4322 - auc_1: 0.9655 - val_loss: 0.3471 - val_auc_1: 0.8307\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4375 - auc_1: 0.9648 - val_loss: 0.3749 - val_auc_1: 0.8391\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4357 - auc_1: 0.9636 - val_loss: 0.3899 - val_auc_1: 0.8322\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4114 - auc_1: 0.9690 - val_loss: 0.3541 - val_auc_1: 0.8322\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4262 - auc_1: 0.9653 - val_loss: 0.3565 - val_auc_1: 0.8305\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4228 - auc_1: 0.9670 - val_loss: 0.4343 - val_auc_1: 0.8312\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4147 - auc_1: 0.9681 - val_loss: 0.3829 - val_auc_1: 0.8349\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4217 - auc_1: 0.9665 - val_loss: 0.3287 - val_auc_1: 0.8447\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4094 - auc_1: 0.9679 - val_loss: 0.3171 - val_auc_1: 0.8337\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4078 - auc_1: 0.9687 - val_loss: 0.3369 - val_auc_1: 0.8396\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4247 - auc_1: 0.9656 - val_loss: 0.4154 - val_auc_1: 0.8349\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4141 - auc_1: 0.9672 - val_loss: 0.3494 - val_auc_1: 0.8315\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4126 - auc_1: 0.9676 - val_loss: 0.4410 - val_auc_1: 0.8148\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3957 - auc_1: 0.9049\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               431104    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 10)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 582,909\n",
      "Trainable params: 581,225\n",
      "Non-trainable params: 1,684\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 4s 32ms/step - loss: 1.3757 - auc_2: 0.5866 - val_loss: 0.8312 - val_auc_2: 0.5000\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.2500 - auc_2: 0.6965 - val_loss: 0.9328 - val_auc_2: 0.4966\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 1.1860 - auc_2: 0.7288 - val_loss: 1.0193 - val_auc_2: 0.4800\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.1432 - auc_2: 0.7506 - val_loss: 1.0190 - val_auc_2: 0.5128\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 1.1071 - auc_2: 0.7657 - val_loss: 0.9548 - val_auc_2: 0.5834\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0789 - auc_2: 0.7694 - val_loss: 0.8623 - val_auc_2: 0.6210\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0488 - auc_2: 0.7891 - val_loss: 0.7431 - val_auc_2: 0.7040\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0316 - auc_2: 0.7925 - val_loss: 0.6800 - val_auc_2: 0.7614\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0111 - auc_2: 0.8028 - val_loss: 0.6617 - val_auc_2: 0.7820\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9957 - auc_2: 0.8119 - val_loss: 0.6775 - val_auc_2: 0.7804\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9817 - auc_2: 0.8107 - val_loss: 0.6548 - val_auc_2: 0.7824\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9658 - auc_2: 0.8160 - val_loss: 0.6462 - val_auc_2: 0.7853\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9599 - auc_2: 0.8227 - val_loss: 0.6347 - val_auc_2: 0.7898\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9471 - auc_2: 0.8273 - val_loss: 0.6215 - val_auc_2: 0.7941\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.9349 - auc_2: 0.8324 - val_loss: 0.6249 - val_auc_2: 0.7928\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9248 - auc_2: 0.8385 - val_loss: 0.6009 - val_auc_2: 0.8040\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9059 - auc_2: 0.8408 - val_loss: 0.5880 - val_auc_2: 0.8015\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.9044 - auc_2: 0.8462 - val_loss: 0.5751 - val_auc_2: 0.8072\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8883 - auc_2: 0.8473 - val_loss: 0.5666 - val_auc_2: 0.8052\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8795 - auc_2: 0.8555 - val_loss: 0.5682 - val_auc_2: 0.8085\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8776 - auc_2: 0.8535 - val_loss: 0.5644 - val_auc_2: 0.8133\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8679 - auc_2: 0.8590 - val_loss: 0.5746 - val_auc_2: 0.8127\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8570 - auc_2: 0.8610 - val_loss: 0.5746 - val_auc_2: 0.8180\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8474 - auc_2: 0.8650 - val_loss: 0.5333 - val_auc_2: 0.8184\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8295 - auc_2: 0.8733 - val_loss: 0.5059 - val_auc_2: 0.8197\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8301 - auc_2: 0.8713 - val_loss: 0.5603 - val_auc_2: 0.8228\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8186 - auc_2: 0.8761 - val_loss: 0.5088 - val_auc_2: 0.8236\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8147 - auc_2: 0.8780 - val_loss: 0.5464 - val_auc_2: 0.8250\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8027 - auc_2: 0.8826 - val_loss: 0.5118 - val_auc_2: 0.8289\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7995 - auc_2: 0.8811 - val_loss: 0.5352 - val_auc_2: 0.8290\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7892 - auc_2: 0.8845 - val_loss: 0.5108 - val_auc_2: 0.8325\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7792 - auc_2: 0.8898 - val_loss: 0.4921 - val_auc_2: 0.8318\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7845 - auc_2: 0.8895 - val_loss: 0.5343 - val_auc_2: 0.8335\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7628 - auc_2: 0.8922 - val_loss: 0.5270 - val_auc_2: 0.8352\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7529 - auc_2: 0.8983 - val_loss: 0.4864 - val_auc_2: 0.8395\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7567 - auc_2: 0.8967 - val_loss: 0.4736 - val_auc_2: 0.8313\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7494 - auc_2: 0.9011 - val_loss: 0.5187 - val_auc_2: 0.8325\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7320 - auc_2: 0.9016 - val_loss: 0.4794 - val_auc_2: 0.8410\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7371 - auc_2: 0.9011 - val_loss: 0.4831 - val_auc_2: 0.8365\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7204 - auc_2: 0.9082 - val_loss: 0.4849 - val_auc_2: 0.8399\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7351 - auc_2: 0.9026 - val_loss: 0.4854 - val_auc_2: 0.8439\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7064 - auc_2: 0.9110 - val_loss: 0.4724 - val_auc_2: 0.8385\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7098 - auc_2: 0.9097 - val_loss: 0.4232 - val_auc_2: 0.8456\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6931 - auc_2: 0.9166 - val_loss: 0.4414 - val_auc_2: 0.8380\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7149 - auc_2: 0.9090 - val_loss: 0.4556 - val_auc_2: 0.8426\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.6761 - auc_2: 0.9162 - val_loss: 0.4816 - val_auc_2: 0.8456\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6937 - auc_2: 0.9161 - val_loss: 0.4357 - val_auc_2: 0.8412\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6742 - auc_2: 0.9191 - val_loss: 0.4460 - val_auc_2: 0.8426\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6688 - auc_2: 0.9211 - val_loss: 0.4642 - val_auc_2: 0.8519\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6618 - auc_2: 0.9229 - val_loss: 0.4117 - val_auc_2: 0.8467\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6556 - auc_2: 0.9254 - val_loss: 0.4504 - val_auc_2: 0.8462\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6564 - auc_2: 0.9249 - val_loss: 0.4273 - val_auc_2: 0.8495\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6471 - auc_2: 0.9261 - val_loss: 0.4224 - val_auc_2: 0.8502\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6461 - auc_2: 0.9277 - val_loss: 0.4435 - val_auc_2: 0.8434\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.6429 - auc_2: 0.9265 - val_loss: 0.4319 - val_auc_2: 0.8469\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6349 - auc_2: 0.9296 - val_loss: 0.3963 - val_auc_2: 0.8427\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6308 - auc_2: 0.9301 - val_loss: 0.4711 - val_auc_2: 0.8516\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6257 - auc_2: 0.9327 - val_loss: 0.4201 - val_auc_2: 0.8528\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6153 - auc_2: 0.9327 - val_loss: 0.3996 - val_auc_2: 0.8472\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6148 - auc_2: 0.9339 - val_loss: 0.4281 - val_auc_2: 0.8436\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6090 - auc_2: 0.9354 - val_loss: 0.3993 - val_auc_2: 0.8439\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6041 - auc_2: 0.9364 - val_loss: 0.4454 - val_auc_2: 0.8554\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5955 - auc_2: 0.9389 - val_loss: 0.3827 - val_auc_2: 0.8510\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6070 - auc_2: 0.9358 - val_loss: 0.4573 - val_auc_2: 0.8565\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5738 - auc_2: 0.9427 - val_loss: 0.4027 - val_auc_2: 0.8514\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5952 - auc_2: 0.9377 - val_loss: 0.4190 - val_auc_2: 0.8589\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5862 - auc_2: 0.9404 - val_loss: 0.3951 - val_auc_2: 0.8565\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5780 - auc_2: 0.9407 - val_loss: 0.3949 - val_auc_2: 0.8529\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5735 - auc_2: 0.9432 - val_loss: 0.3665 - val_auc_2: 0.8453\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5642 - auc_2: 0.9454 - val_loss: 0.4019 - val_auc_2: 0.8524\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5608 - auc_2: 0.9449 - val_loss: 0.3989 - val_auc_2: 0.8561\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5598 - auc_2: 0.9441 - val_loss: 0.4317 - val_auc_2: 0.8551\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5635 - auc_2: 0.9465 - val_loss: 0.5244 - val_auc_2: 0.8512\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5609 - auc_2: 0.9454 - val_loss: 0.3684 - val_auc_2: 0.8551\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5449 - auc_2: 0.9474 - val_loss: 0.4654 - val_auc_2: 0.8615\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5458 - auc_2: 0.9476 - val_loss: 0.4361 - val_auc_2: 0.8505\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5352 - auc_2: 0.9503 - val_loss: 0.4004 - val_auc_2: 0.8530\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5429 - auc_2: 0.9482 - val_loss: 0.4158 - val_auc_2: 0.8595\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5324 - auc_2: 0.9496 - val_loss: 0.4472 - val_auc_2: 0.8548\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5414 - auc_2: 0.9476 - val_loss: 0.3440 - val_auc_2: 0.8534\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5225 - auc_2: 0.9534 - val_loss: 0.3903 - val_auc_2: 0.8504\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5306 - auc_2: 0.9496 - val_loss: 0.4865 - val_auc_2: 0.8587\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5284 - auc_2: 0.9498 - val_loss: 0.4335 - val_auc_2: 0.8498\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5141 - auc_2: 0.9544 - val_loss: 0.3584 - val_auc_2: 0.8559\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5007 - auc_2: 0.9563 - val_loss: 0.3476 - val_auc_2: 0.8585\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5251 - auc_2: 0.9504 - val_loss: 0.4390 - val_auc_2: 0.8447\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5015 - auc_2: 0.9558 - val_loss: 0.4391 - val_auc_2: 0.8553\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4900 - auc_2: 0.9571 - val_loss: 0.4082 - val_auc_2: 0.8487\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5064 - auc_2: 0.9547 - val_loss: 0.3305 - val_auc_2: 0.8364\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4990 - auc_2: 0.9553 - val_loss: 0.4313 - val_auc_2: 0.8544\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4994 - auc_2: 0.9556 - val_loss: 0.3830 - val_auc_2: 0.8476\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4914 - auc_2: 0.9567 - val_loss: 0.3170 - val_auc_2: 0.8429\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4904 - auc_2: 0.9574 - val_loss: 0.3563 - val_auc_2: 0.8532\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4797 - auc_2: 0.9579 - val_loss: 0.4003 - val_auc_2: 0.8553\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4806 - auc_2: 0.9598 - val_loss: 0.3743 - val_auc_2: 0.8566\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4708 - auc_2: 0.9599 - val_loss: 0.3466 - val_auc_2: 0.8620\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4722 - auc_2: 0.9601 - val_loss: 0.3032 - val_auc_2: 0.8511\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4740 - auc_2: 0.9596 - val_loss: 0.3724 - val_auc_2: 0.8619\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4731 - auc_2: 0.9598 - val_loss: 0.3422 - val_auc_2: 0.8475\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4559 - auc_2: 0.9636 - val_loss: 0.3476 - val_auc_2: 0.8626\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4587 - auc_2: 0.9613 - val_loss: 0.3881 - val_auc_2: 0.8521\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4674 - auc_2: 0.9607 - val_loss: 0.3886 - val_auc_2: 0.8564\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4593 - auc_2: 0.9621 - val_loss: 0.3870 - val_auc_2: 0.8479\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4480 - auc_2: 0.9642 - val_loss: 0.3110 - val_auc_2: 0.8554\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4520 - auc_2: 0.9632 - val_loss: 0.4200 - val_auc_2: 0.8455\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4399 - auc_2: 0.9659 - val_loss: 0.3820 - val_auc_2: 0.8585\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4472 - auc_2: 0.9628 - val_loss: 0.3742 - val_auc_2: 0.8635\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4368 - auc_2: 0.9654 - val_loss: 0.4100 - val_auc_2: 0.8665\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4418 - auc_2: 0.9634 - val_loss: 0.2919 - val_auc_2: 0.8491\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4400 - auc_2: 0.9647 - val_loss: 0.4239 - val_auc_2: 0.8588\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4392 - auc_2: 0.9648 - val_loss: 0.4179 - val_auc_2: 0.8539\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4241 - auc_2: 0.9675 - val_loss: 0.3633 - val_auc_2: 0.8608\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4240 - auc_2: 0.9662 - val_loss: 0.3654 - val_auc_2: 0.8532\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4228 - auc_2: 0.9667 - val_loss: 0.3505 - val_auc_2: 0.8557\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4254 - auc_2: 0.9661 - val_loss: 0.3536 - val_auc_2: 0.8511\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4380 - auc_2: 0.9638 - val_loss: 0.3616 - val_auc_2: 0.8400\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4300 - auc_2: 0.9652 - val_loss: 0.7570 - val_auc_2: 0.7770\n",
      "Epoch 118/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4248 - auc_2: 0.9659 - val_loss: 0.3473 - val_auc_2: 0.8453\n",
      "Epoch 119/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4115 - auc_2: 0.9683 - val_loss: 0.3488 - val_auc_2: 0.8515\n",
      "Epoch 120/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4124 - auc_2: 0.9685 - val_loss: 0.3658 - val_auc_2: 0.8514\n",
      "Epoch 121/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3984 - auc_2: 0.9699 - val_loss: 0.3652 - val_auc_2: 0.8607\n",
      "Epoch 122/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4241 - auc_2: 0.9657 - val_loss: 0.3446 - val_auc_2: 0.8609\n",
      "Epoch 123/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4047 - auc_2: 0.9689 - val_loss: 0.3473 - val_auc_2: 0.8478\n",
      "Epoch 124/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4082 - auc_2: 0.9684 - val_loss: 0.3780 - val_auc_2: 0.8561\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3234 - auc_2: 0.9263\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 512)               431104    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 512)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_15 (ReLU)             (None, 10)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 582,909\n",
      "Trainable params: 581,225\n",
      "Non-trainable params: 1,684\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 4s 32ms/step - loss: 1.1575 - auc_3: 0.6153 - val_loss: 0.6228 - val_auc_3: 0.5000\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0666 - auc_3: 0.7210 - val_loss: 0.6497 - val_auc_3: 0.5209\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0365 - auc_3: 0.7465 - val_loss: 0.7130 - val_auc_3: 0.5618\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.0209 - auc_3: 0.7635 - val_loss: 0.7455 - val_auc_3: 0.6351\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9984 - auc_3: 0.7807 - val_loss: 0.7298 - val_auc_3: 0.6453\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.9736 - auc_3: 0.7889 - val_loss: 0.6333 - val_auc_3: 0.6911\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.9623 - auc_3: 0.8030 - val_loss: 0.5518 - val_auc_3: 0.7322\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.9565 - auc_3: 0.8029 - val_loss: 0.5201 - val_auc_3: 0.7625\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.9341 - auc_3: 0.8190 - val_loss: 0.5285 - val_auc_3: 0.7736\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9287 - auc_3: 0.8214 - val_loss: 0.5426 - val_auc_3: 0.7744\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9173 - auc_3: 0.8241 - val_loss: 0.5574 - val_auc_3: 0.7769\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9062 - auc_3: 0.8276 - val_loss: 0.5504 - val_auc_3: 0.7833\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9041 - auc_3: 0.8353 - val_loss: 0.5110 - val_auc_3: 0.7889\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8898 - auc_3: 0.8398 - val_loss: 0.5299 - val_auc_3: 0.7927\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8823 - auc_3: 0.8447 - val_loss: 0.5398 - val_auc_3: 0.7961\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8682 - auc_3: 0.8515 - val_loss: 0.5356 - val_auc_3: 0.8006\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8623 - auc_3: 0.8485 - val_loss: 0.5138 - val_auc_3: 0.8028\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8616 - auc_3: 0.8537 - val_loss: 0.4882 - val_auc_3: 0.8009\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8411 - auc_3: 0.8592 - val_loss: 0.4991 - val_auc_3: 0.8126\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8415 - auc_3: 0.8610 - val_loss: 0.5320 - val_auc_3: 0.8030\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8279 - auc_3: 0.8673 - val_loss: 0.5211 - val_auc_3: 0.8158\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8232 - auc_3: 0.8703 - val_loss: 0.5139 - val_auc_3: 0.8150\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8186 - auc_3: 0.8700 - val_loss: 0.5077 - val_auc_3: 0.8162\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7991 - auc_3: 0.8792 - val_loss: 0.4791 - val_auc_3: 0.8173\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7935 - auc_3: 0.8803 - val_loss: 0.5087 - val_auc_3: 0.8216\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7914 - auc_3: 0.8792 - val_loss: 0.4980 - val_auc_3: 0.8216\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7854 - auc_3: 0.8823 - val_loss: 0.4945 - val_auc_3: 0.8202\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7739 - auc_3: 0.8881 - val_loss: 0.4775 - val_auc_3: 0.8191\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7605 - auc_3: 0.8926 - val_loss: 0.5174 - val_auc_3: 0.8228\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7685 - auc_3: 0.8869 - val_loss: 0.5040 - val_auc_3: 0.8252\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7449 - auc_3: 0.8972 - val_loss: 0.4507 - val_auc_3: 0.8315\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7472 - auc_3: 0.8952 - val_loss: 0.4771 - val_auc_3: 0.8220\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7498 - auc_3: 0.8983 - val_loss: 0.5099 - val_auc_3: 0.8241\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7314 - auc_3: 0.8992 - val_loss: 0.4455 - val_auc_3: 0.8302\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7262 - auc_3: 0.9021 - val_loss: 0.4739 - val_auc_3: 0.8283\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7216 - auc_3: 0.9048 - val_loss: 0.4419 - val_auc_3: 0.8333\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7253 - auc_3: 0.9046 - val_loss: 0.4988 - val_auc_3: 0.8322\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6960 - auc_3: 0.9097 - val_loss: 0.4947 - val_auc_3: 0.8318\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7045 - auc_3: 0.9094 - val_loss: 0.4244 - val_auc_3: 0.8358\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6902 - auc_3: 0.9134 - val_loss: 0.4930 - val_auc_3: 0.8377\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6953 - auc_3: 0.9131 - val_loss: 0.4318 - val_auc_3: 0.8363\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6754 - auc_3: 0.9165 - val_loss: 0.4530 - val_auc_3: 0.8341\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6762 - auc_3: 0.9177 - val_loss: 0.4736 - val_auc_3: 0.8274\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6725 - auc_3: 0.9183 - val_loss: 0.4186 - val_auc_3: 0.8470\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6675 - auc_3: 0.9216 - val_loss: 0.4275 - val_auc_3: 0.8387\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6488 - auc_3: 0.9216 - val_loss: 0.4381 - val_auc_3: 0.8337\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6669 - auc_3: 0.9199 - val_loss: 0.4923 - val_auc_3: 0.8233\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6403 - auc_3: 0.9262 - val_loss: 0.4295 - val_auc_3: 0.8357\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6419 - auc_3: 0.9258 - val_loss: 0.4365 - val_auc_3: 0.8359\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6384 - auc_3: 0.9255 - val_loss: 0.3879 - val_auc_3: 0.8380\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6364 - auc_3: 0.9277 - val_loss: 0.4928 - val_auc_3: 0.8421\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6292 - auc_3: 0.9293 - val_loss: 0.4302 - val_auc_3: 0.8341\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6182 - auc_3: 0.9316 - val_loss: 0.4449 - val_auc_3: 0.8323\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6145 - auc_3: 0.9341 - val_loss: 0.3927 - val_auc_3: 0.8404\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6089 - auc_3: 0.9337 - val_loss: 0.4436 - val_auc_3: 0.8304\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6057 - auc_3: 0.9343 - val_loss: 0.4335 - val_auc_3: 0.8375\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6011 - auc_3: 0.9356 - val_loss: 0.4684 - val_auc_3: 0.8477\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6014 - auc_3: 0.9356 - val_loss: 0.3750 - val_auc_3: 0.8451\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5935 - auc_3: 0.9363 - val_loss: 0.4074 - val_auc_3: 0.8387\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5808 - auc_3: 0.9400 - val_loss: 0.4128 - val_auc_3: 0.8369\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5833 - auc_3: 0.9395 - val_loss: 0.4118 - val_auc_3: 0.8396\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5816 - auc_3: 0.9391 - val_loss: 0.4244 - val_auc_3: 0.8385\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5776 - auc_3: 0.9395 - val_loss: 0.4322 - val_auc_3: 0.8450\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5702 - auc_3: 0.9432 - val_loss: 0.4455 - val_auc_3: 0.8407\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5635 - auc_3: 0.9414 - val_loss: 0.4081 - val_auc_3: 0.8452\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5622 - auc_3: 0.9439 - val_loss: 0.4311 - val_auc_3: 0.8353\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5607 - auc_3: 0.9441 - val_loss: 0.4173 - val_auc_3: 0.8336\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5487 - auc_3: 0.9449 - val_loss: 0.3747 - val_auc_3: 0.8367\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5578 - auc_3: 0.9442 - val_loss: 0.4040 - val_auc_3: 0.8388\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5464 - auc_3: 0.9464 - val_loss: 0.4252 - val_auc_3: 0.8425\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5386 - auc_3: 0.9473 - val_loss: 0.4228 - val_auc_3: 0.8425\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5323 - auc_3: 0.9483 - val_loss: 0.4171 - val_auc_3: 0.8471\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5422 - auc_3: 0.9482 - val_loss: 0.3888 - val_auc_3: 0.8413\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5436 - auc_3: 0.9470 - val_loss: 0.3360 - val_auc_3: 0.8448\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5200 - auc_3: 0.9506 - val_loss: 0.4375 - val_auc_3: 0.8414\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5171 - auc_3: 0.9521 - val_loss: 0.4668 - val_auc_3: 0.8466\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5128 - auc_3: 0.9526 - val_loss: 0.3874 - val_auc_3: 0.8465\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.5101 - auc_3: 0.9533 - val_loss: 0.3890 - val_auc_3: 0.8482\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.5050 - auc_3: 0.9535 - val_loss: 0.3646 - val_auc_3: 0.8423\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5079 - auc_3: 0.9530 - val_loss: 0.4265 - val_auc_3: 0.8447\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5187 - auc_3: 0.9515 - val_loss: 0.3314 - val_auc_3: 0.8425\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5033 - auc_3: 0.9536 - val_loss: 0.3839 - val_auc_3: 0.8389\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4914 - auc_3: 0.9564 - val_loss: 0.4024 - val_auc_3: 0.8449\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4960 - auc_3: 0.9551 - val_loss: 0.3800 - val_auc_3: 0.8432\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4812 - auc_3: 0.9584 - val_loss: 0.3618 - val_auc_3: 0.8489\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4970 - auc_3: 0.9545 - val_loss: 0.3238 - val_auc_3: 0.8441\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4776 - auc_3: 0.9585 - val_loss: 0.3672 - val_auc_3: 0.8432\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4735 - auc_3: 0.9578 - val_loss: 0.4112 - val_auc_3: 0.8454\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4807 - auc_3: 0.9581 - val_loss: 0.3539 - val_auc_3: 0.8417\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4721 - auc_3: 0.9590 - val_loss: 0.3939 - val_auc_3: 0.8404\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4646 - auc_3: 0.9610 - val_loss: 0.4101 - val_auc_3: 0.8544\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.4740 - auc_3: 0.9577 - val_loss: 0.3779 - val_auc_3: 0.8477\n",
      "Epoch 93/500\n",
      " 61/100 [=================>............] - ETA: 0s - loss: 0.4853 - auc_3: 0.9564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=9, random_state = 2023, shuffle = True)\n",
    "for i, (train_index, val_index) in enumerate(skf.split(train_data, train_lab)):\n",
    "    train = train_data[train_index,:]\n",
    "    train_label = train_lab[train_index]\n",
    "    valid = train_data[val_index,:]\n",
    "    valid_label = train_lab[val_index]\n",
    "\n",
    "    tlen = train.shape[0]\n",
    "    vlen = valid.shape[0] \n",
    "    \n",
    "    train = tf.data.Dataset.from_tensor_slices((train, train_label))\n",
    "    train = train.shuffle(tlen, seed = 2022)\n",
    "    train = train.batch(config.batch_size)\n",
    "    train = train.repeat(1000)\n",
    "    \n",
    "    valid = tf.data.Dataset.from_tensor_slices((valid, valid_label))\n",
    "    valid = valid.shuffle(vlen, seed = 2022)\n",
    "    valid = valid.batch(config.batch_size)\n",
    "    valid = valid.repeat(1000)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(841,)))\n",
    "    model.add(tf.keras.layers.Dense(config.L2))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dense(config.L3))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dense(config.L5))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dense(config.L6))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dense(config.outl, activation = config.outact))\n",
    "    \n",
    "    model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001), \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics=[tf.keras.metrics.AUC()])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(train, epochs=config.epochs,validation_data = valid, validation_batch_size = config.batch_size, \n",
    "                        validation_steps = 200,validation_freq = 1,steps_per_epoch=config.steps_per, callbacks = [callback], \n",
    "                        class_weight = {0:1, 1:10})\n",
    "    \n",
    "    model.evaluate(test, test_lab, batch_size = config.batch_size)\n",
    "    \n",
    "    model.save(\"../models/BNrelu256be_3SGDes15wc\" + str(i) + \"Fold.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e51002-57b0-4316-adc8-f6df21582894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "auc = history.history['auc']\n",
    "val_loss = history.history['val_loss']\n",
    "val_auc = history.history['val_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b947bc-297a-4435-81bc-ce6656759513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc0700-39f0-4c18-abc5-169e03715c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epoch, loss, label='Loss')  \n",
    "ax.plot(epoch, auc, label='AUC') \n",
    "ax.set_xlabel('epochs')  \n",
    "ax.set_ylabel('rate')  \n",
    "ax.set_title(\"Using SGD 0.001 optimizer\")\n",
    "ax.legend()\n",
    "plt.savefig(\"../figures/BNrelu256be_3SGDes18.pdf\",dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e958d66-a801-4387-8124-77209929baed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epoch, val_loss, label='val_Loss')  \n",
    "ax.plot(epoch, val_auc, label='val_AUC') \n",
    "ax.set_xlabel('epochs')  \n",
    "ax.set_ylabel('rate')  \n",
    "ax.set_title(\"Using SGD 0.001 optimizer\")\n",
    "ax.legend()\n",
    "plt.savefig(\"../figures/val_BNrelu256be_3SGDes18.pdf\",dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08951e1f-30da-46ba-96db-c1f4ce817893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
